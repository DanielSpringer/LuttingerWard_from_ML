{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca614bf7-125b-4848-928e-bae8592bf102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.jp-Cell { width: 100% !important; margin-left:00px}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.jp-Cell { width: 100% !important; margin-left:00px}</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "392c9d3d-3931-4ed2-8dc9-a793866236db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install torch-geometric\n",
    "# !pip install pytorch-lightning\n",
    "# !pip install h5py\n",
    "# !pip install matplotlib\n",
    "# !pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5ee9c2-fc84-4eaf-b51e-c9636757549a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A100-PCIE-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: ../saves/TEST/U2c0_b30.0_metiso_1/save_auto_encoder_BS10_2024-07-28\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type         | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | model         | auto_encoder | 307 K  | train\n",
      "1 | criterion_mse | MSELoss      | 0      | train\n",
      "-------------------------------------------------------\n",
      "307 K     Trainable params\n",
      "0         Non-trainable params\n",
      "307 K     Total params\n",
      "1.231     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fs72150/springerd/.local/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:475: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/home/fs72150/springerd/.local/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n",
      "/home/fs72150/springerd/.local/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "371614f2333a4f0a815940d31a405c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/gpfs/data/fs72150/springerd/Projects/LuttingerWard_from_ML/code/')\n",
    "import torch\n",
    "# from models import models as models\n",
    "# from wrappers import wrapers\n",
    "from torch.utils.data import DataLoader\n",
    "import load_data\n",
    "import datetime\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.plugins.environments import LightningEnvironment\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def train():\n",
    "    ### JSON File contains full information about entire run (model, data, hyperparameters)\n",
    "    ### TODO \n",
    "    MODEL_NAME = \"AUTO_ENCODER_1\"\n",
    "    config = json.load(open('../configs/confmod_auto_encoder.json'))[MODEL_NAME]\n",
    "    # MODEL_NAME = \"AUTO_ENCODER_1\"\n",
    "    # config = json.load(open('confmod_auto_encoder.json'))[MODEL_NAME]\n",
    "\n",
    "    ''' Dataloading '''\n",
    "    ### > Separate training and validation HDF5 files \n",
    "    # rand_samples = torch.randint(0,1000,(100,), dtype=int)\n",
    "    # sample_idxs = torch.ones(100, dtype=int) * 941\n",
    "    # sample_idx = torch.cat([sample_idxs, rand_samples], axis=0)\n",
    "    # sample_idx, _ = torch.sort(sample_idx)\n",
    "    # ld = __import__(\"load_data\", fromlist=['object'])\n",
    "    # train_set = getattr(ld, config[\"DATA_LOADER\"])(config, data_type = \"valid\", target_sample = sample_idx)\n",
    "    # # validation_set = getattr(ld, config[\"DATA_LOADER\"])(config, data_type = \"valid\")\n",
    "    # train_dataloader = DataLoader(train_set, batch_size=config[\"batch_size\"], shuffle=True, num_workers=8, persistent_workers=True, pin_memory=True)\n",
    "    # # validation_dataloader = DataLoader(validation_set, batch_size=config[\"batch_size\"], shuffle=False, num_workers=8, persistent_workers=True, pin_memory=True)\n",
    "    \n",
    "    ### > Single HDF5 file containing training and validation data \n",
    "    ld = __import__(\"load_data\", fromlist=['object'])\n",
    "    # data_set = load_data.Dataset_ae(config)\n",
    "    data_set = getattr(ld, config[\"DATA_LOADER\"])(config, data_type = \"insulating\")\n",
    "    train_set, validation_set = torch.utils.data.random_split(data_set, [int(data_set.__len__()*0.8), (data_set.__len__()-int(data_set.__len__()*0.8))], generator=torch.Generator().manual_seed(42))\n",
    "    train_dataloader = DataLoader(train_set, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    validation_dataloader = DataLoader(validation_set, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "\n",
    "\n",
    "    ''' Model setup '''\n",
    "    wrapers = __import__(\"wrappers.wrapers\", fromlist=['object'])#.wrapers\n",
    "    # import sys, inspect\n",
    "    # for name, clazz in inspect.getmembers(wrapers):\n",
    "    #     print(name)\n",
    "    #     if inspect.isclass(clazz):\n",
    "    #         print(clazz)\n",
    "    model = getattr(wrapers, config[\"MODEL_WRAPER\"])(config)\n",
    "    \n",
    "    ''' Model loading from save file '''\n",
    "    if config[\"continue\"] == True:\n",
    "        SAVEPATH = config[\"SAVEPATH\"]\n",
    "        checkpoint = torch.load(SAVEPATH)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        print(\" >>> Loaded checkpoint\")\n",
    "\n",
    "\n",
    "    ''' Logging and saving '''\n",
    "    DATA_NAME = os.path.splitext(os.path.basename(config[\"PATH_TRAIN\"]))[0]\n",
    "\n",
    "    PATH = \"\"\n",
    "    CONFIGURATION = f\"../saves/TEST/{DATA_NAME}/save_{config['MODEL_NAME']}_BS{config['batch_size']}_{datetime.datetime.now().date()}\"\n",
    "    # CONFIGURATION = f\"../saves/save_{config['MODEL_NAME']}_Nodes{config['n_nodes']}_BS{config['batch_size']}_{datetime.datetime.now().date()}\"\n",
    "    logger = TensorBoardLogger(PATH, name=CONFIGURATION)\n",
    "\n",
    "\n",
    "    # '''Define (pytorch_lightning) Trainer '''\n",
    "    # ### > SLURM Training\n",
    "    # trainer = pl.Trainer(max_epochs=config[\"epochs\"], accelerator=config[\"device_type\"], devices=config[\"devices\"], num_nodes=config[\"num_nodes\"], strategy='ddp', logger=logger)\n",
    "    # ### > Jupyter Notebook Training\n",
    "    trainer = pl.Trainer(max_epochs=config[\"epochs\"], accelerator=config[\"device_type\"], devices=1, strategy='auto', logger=logger, plugins=[LightningEnvironment()])\n",
    "    # ### > Jupyter Notebook CPU Training\n",
    "    # trainer = pl.Trainer(max_epochs=1, accelerator='cpu', devices=1, strategy='auto', logger=logger, plugins=[LightningEnvironment()])\n",
    "    \n",
    "    ''' Train '''\n",
    "    trainer.fit(model, train_dataloader, validation_dataloader)\n",
    "    # trainer.fit(model, train_dataloader)\n",
    "    \n",
    "    ''' Saving configuration file into log folder ''' \n",
    "    LOGDIR = trainer.log_dir\n",
    "    json_object = json.dumps(config, indent=4)\n",
    "    with open(LOGDIR+\"/config.json\", \"w\") as outfile:\n",
    "        outfile.write(json_object)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    train()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c592551-187a-47ea-a5d9-374942a85a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
