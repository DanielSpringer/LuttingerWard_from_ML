{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb48f2e9-5730-45fb-bd57-79294cf57441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"colab\"\n",
    "\n",
    "\n",
    "def plot3D_4x(P, TITLES):\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=4,\n",
    "        specs=[[{'type': 'surface'},{'type': 'surface'},{'type': 'surface'},{'type': 'surface'}]],\n",
    "        subplot_titles=TITLES)# , subplot_titles=(titles))\n",
    "    \n",
    "    omega = 1\n",
    "    q = 41\n",
    "    \n",
    "    fig.add_trace(\n",
    "    go.Surface(z=P[0], colorscale='viridis', showscale=False),\n",
    "    row=1, col=1)\n",
    "    \n",
    "    fig.add_trace(\n",
    "    go.Surface(z=P[1], colorscale='viridis', showscale=False),\n",
    "    row=1, col=2)\n",
    "    \n",
    "    fig.add_trace(\n",
    "    go.Surface(z=P[2], colorscale='viridis', showscale=False),\n",
    "    row=1, col=3)\n",
    "    \n",
    "    fig.add_trace(\n",
    "    go.Surface(z=P[3], colorscale='viridis', showscale=False),\n",
    "    row=1, col=4)\n",
    "    \n",
    "    fig.update_scenes(xaxis_title_text='ek',  \n",
    "                      yaxis_title_text='vk')\n",
    "        \n",
    "    camera = dict(\n",
    "        eye=dict(x=2, y=1.5, z=1.)\n",
    "    )\n",
    "    aspectratio = dict(x=1, y=1., z=1.5)\n",
    "    \n",
    "        \n",
    "    fig.layout.scene1.camera = camera\n",
    "    fig.layout.scene2.camera = camera\n",
    "    fig.layout.scene3.camera = camera\n",
    "    fig.layout.scene4.camera = camera\n",
    "    fig.layout.scene1.aspectratio=aspectratio\n",
    "    fig.layout.scene2.aspectratio=aspectratio\n",
    "    fig.layout.scene3.aspectratio=aspectratio\n",
    "    fig.layout.scene4.aspectratio=aspectratio\n",
    "    \n",
    "    fig.update_layout(\n",
    "        scene1 = dict(zaxis = dict(nticks=4),),\n",
    "        scene2 = dict(zaxis = dict(nticks=4),),\n",
    "        scene3 = dict(zaxis = dict(nticks=4),),\n",
    "        scene4 = dict(zaxis = dict(nticks=4),),\n",
    "        title=r'',\n",
    "        autosize=True,\n",
    "        width=1800, height=600,\n",
    "        margin=dict(l=10, r=5, b=0, t=35))\n",
    "    \n",
    "    fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c38f9a16-ffab-4350-9840-971978aaee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def fit_ImSigma_2(iw, gamma, alpha, beta):\n",
    "    ImSigma = -gamma - alpha * iw - beta * iw**2\n",
    "    return ImSigma\n",
    "\n",
    "def fit_ImSigma_1(iw, gamma, alpha):\n",
    "    ImSigma = gamma - alpha * iw\n",
    "    return ImSigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5a598c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/data/fs72150/springerd/Projects/LuttingerWard_from_ML/saves/Herbert/GTrans/AE/U2c0_b30_N250000/save_auto_encoder_BS10_2024-12-16/version_0/checkpoints/epoch=299-step=3697500.ckpt\n",
      "Dataset_generic\n",
      " Checkpoint loaded...\n",
      " working 1 ...\n",
      " Model loading... \n",
      " Model loaded... \n",
      "...loading done.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import sys, re\n",
    "sys.path.append('/gpfs/data/fs72150/springerd/Projects/LuttingerWard_from_ML/')\n",
    "\n",
    "import torch\n",
    "import json\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "def create_datasets(config):\n",
    "    \n",
    "    PATH = config[\"PATH_TRAIN\"]\n",
    "\n",
    "    # f = h5py.File(PATH, 'r')\n",
    "    # data = np.array(f[\"train\"]['data'][:1000])\n",
    "    # print(\"************************************\")\n",
    "    # print(\"Size of dataset: \", data.shape)\n",
    "    # print(\"************************************\")\n",
    "    # train, validation = torch.utils.data.random_split(data, [int(data.__len__()*0.8), int(data.__len__())-int(data.__len__()*0.8)], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    PATH = config[\"PATH_TRAIN\"]\n",
    "    f = h5py.File(PATH, 'r')\n",
    "    if config[\"TRAINDATA\"]==config[\"VALIDATIONDATA\"]:\n",
    "        data = np.array(f[config[\"TRAINDATA\"]])\n",
    "        train, validation = torch.utils.data.random_split(data, [int(data.__len__()*config[\"SPLIT\"]), int(data.__len__())-int(data.__len__()*config[\"SPLIT\"])], generator=torch.Generator().manual_seed(42))\n",
    "    else:\n",
    "        train = np.array(f[config[\"TRAINDATA\"]])\n",
    "        validation = np.array(f[config[\"VALIDATIONDATA\"]])\n",
    "    \n",
    "    return train, validation\n",
    "\n",
    "def load_model_data(SAVEPATH):\n",
    "    ep = 0\n",
    "    for filename in os.listdir(SAVEPATH+\"checkpoints\"):\n",
    "        epc = int(re.findall(r'\\d+', filename)[0])\n",
    "        # if epc == 0:\n",
    "        #     f = os.path.join(SAVEPATH, filename)\n",
    "        #     FILENAME = \"checkpoints/\"+filename\n",
    "        if epc > ep:\n",
    "            f = os.path.join(SAVEPATH, filename)\n",
    "            FILENAME = \"checkpoints/\"+filename\n",
    "            ep = epc\n",
    "    config = json.load(open(SAVEPATH+'config.json'))\n",
    "    print(SAVEPATH+FILENAME)\n",
    "    print(config[\"DATA_LOADER\"])\n",
    "    checkpoint = torch.load(SAVEPATH+FILENAME, map_location=torch.device('cpu'))\n",
    "    print(\" Checkpoint loaded...\")\n",
    "    \n",
    "    ''' Model setup '''\n",
    "    wrapers = __import__(\"src.wrappers.wrapers\", fromlist=['object'])#.wrapers\n",
    "    print(\" working 1 ...\")\n",
    "    model = getattr(wrapers, config[\"MODEL_WRAPER\"])(config)\n",
    "    print(\" Model loading... \")\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    print(\" Model loaded... \")\n",
    "    # p = kk\n",
    "    # model = 0\n",
    "\n",
    "    ''' Dataloading '''\n",
    "    train_data, validation_data = create_datasets(config)\n",
    "    train_data = np.array(train_data)\n",
    "    validation_data = np.array(validation_data)\n",
    "    \n",
    "    ### > Single HDF5 file containing training and validation data \n",
    "    ld = __import__(\"load_data\", fromlist=['object'])\n",
    "    # data_set = load_data.Dataset_ae(config)\n",
    "    train_set = getattr(ld, config[\"DATA_LOADER\"])(config, train_data)\n",
    "    validation_set = getattr(ld, config[\"DATA_LOADER\"])(config, validation_data)\n",
    "\n",
    "    train_dataloader = DataLoader(train_set, batch_size=22, shuffle=True)\n",
    "    validation_dataloader = DataLoader(validation_set, batch_size=22, shuffle=True)\n",
    "    \n",
    "    # f = h5py.File(config[\"PATH_TRAIN\"], 'r')\n",
    "    # parameters = f[\"valid\"][\"parameters\"]\n",
    "    return model, train_set, validation_set, train_dataloader, validation_dataloader, config\n",
    "\n",
    "SAVEPATH = \"/gpfs/data/fs72150/springerd/Projects/LuttingerWard_from_ML/saves/Herbert/GTrans/AE/U2c0_b30_N250000/save_auto_encoder_BS10_2024-12-16/version_0/\"\n",
    "model, train_set, validation_set, train_dataloader, validation_dataloader, config = load_model_data(SAVEPATH)\n",
    "model.model.eval()\n",
    "\n",
    "\n",
    "print(\"...loading done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bec5b1c-b41f-487b-bf7b-3be782e91abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/gpfs/data/fs72150/springerd/Projects/LuttingerWard_from_ML/data/GTrans/U2c0_b30_N250000.hdf5\"\n",
    "f = h5py.File(PATH, 'r')\n",
    "\n",
    "train = np.array(f[\"metiso/data/30.0\"])\n",
    "valid = np.array(f[\"transprox/data/30.0\"])\n",
    "\n",
    "train_para = np.array(f[\"metiso/parameters/30.0\"])\n",
    "valid_para = np.array(f[\"transprox/parameters/30.0\"])\n",
    "\n",
    "# print(valid_para[1])\n",
    "\n",
    "### Unique parameters\n",
    "unique_ek = []\n",
    "unique_vk = [] \n",
    "unique_beta = [] \n",
    "\n",
    "for n,para in enumerate(valid_para):\n",
    "    if para[1] not in unique_ek:\n",
    "        unique_ek.append(para[1])\n",
    "    if para[2] not in unique_vk:\n",
    "        unique_vk.append(para[2])\n",
    "    if para[0] not in unique_beta:\n",
    "        unique_beta.append(para[0])\n",
    "\n",
    "for n,para in enumerate(train_para):\n",
    "    if para[1] not in unique_ek:\n",
    "        unique_ek.append(para[1])\n",
    "    if para[2] not in unique_vk:\n",
    "        unique_vk.append(para[2])\n",
    "    if para[0] not in unique_beta:\n",
    "        unique_beta.append(para[0])\n",
    "\n",
    "unique_beta = np.array(unique_beta)\n",
    "unique_ek = np.array(unique_ek)\n",
    "unique_vk = np.array(unique_vk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "789fd335-dcfd-45bf-97af-46a63f9b3faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "for n,para in enumerate(valid_para):\n",
    "    if para[1] not in data.keys():\n",
    "        data[para[1]] = {}\n",
    "    if para[2] not in data[para[1]].keys():\n",
    "        data[para[1]][para[2]] = {}\n",
    "\n",
    "    data[para[1]][para[2]][\"input\"] = torch.tensor(valid[n][0])\n",
    "    data[para[1]][para[2]][\"target\"] = torch.tensor(valid[n][1])\n",
    "    data[para[1]][para[2]][\"param\"] = [para[1], para[2]]\n",
    "    data[para[1]][para[2]][\"set\"] = 1\n",
    "\n",
    "for n,para in enumerate(train_para):\n",
    "    if para[1] not in data.keys():\n",
    "        data[para[1]] = {}\n",
    "    if para[2] not in data[para[1]].keys():\n",
    "        data[para[1]][para[2]] = {}\n",
    "\n",
    "    data[para[1]][para[2]][\"input\"] = torch.tensor(train[n][0])\n",
    "    data[para[1]][para[2]][\"target\"] = torch.tensor(train[n][1])\n",
    "    data[para[1]][para[2]][\"param\"] = [para[1], para[2]]\n",
    "    data[para[1]][para[2]][\"set\"] = -1\n",
    "\n",
    "sort_ek = np.sort(unique_ek)\n",
    "sort_vk = np.sort(unique_vk)\n",
    "\n",
    "data_np = np.zeros((sort_ek.shape[0],sort_vk.shape[0],3,1000), dtype=complex)\n",
    "para_np = np.zeros((sort_ek.shape[0],sort_vk.shape[0],2))\n",
    "trainvalid = np.zeros((sort_ek.shape[0],sort_vk.shape[0]))\n",
    "\n",
    "\n",
    "for n in range(0,sort_ek.shape[0]):\n",
    "    if n%100==0: print(n)\n",
    "    for m in range(0,sort_vk.shape[0]):\n",
    "        trainvalid[n,m] = data[sort_ek[n]][sort_vk[m]][\"set\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beffae8b-ae7f-4731-9dcc-56a2cb0ca231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1144935/3028773937.py:4: DeprecationWarning:\n",
      "\n",
      "__array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "\n",
      "/tmp/ipykernel_1144935/3028773937.py:5: DeprecationWarning:\n",
      "\n",
      "__array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "for n in range(0,sort_ek.shape[0]):\n",
    "    if n%100==0: print(n)\n",
    "    for m in range(0,sort_vk.shape[0]):\n",
    "        data_np[n,m,0,:] = data[sort_ek[n]][sort_vk[m]][\"input\"]\n",
    "        data_np[n,m,1,:] = data[sort_ek[n]][sort_vk[m]][\"target\"]\n",
    "        data_np[n,m,2,:] = model(data[sort_ek[n]][sort_vk[m]][\"input\"].imag.float()).detach().numpy()\n",
    "        para_np[n,m,0] = sort_ek[n]\n",
    "        para_np[n,m,1] = sort_vk[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a931bf3d-60e8-4463-9943-32f3671cabf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.MSELoss()\n",
    "mse_loss = torch.zeros((sort_ek.shape[0], sort_vk.shape[0]))\n",
    "for n in range(0,sort_ek.shape[0]):\n",
    "    if n%100==0: print(n)\n",
    "    for m in range(0,sort_vk.shape[0]):\n",
    "        mse_loss[n,m] = loss(torch.tensor(data_np[n,m,1,:].imag), torch.tensor(data_np[n,m,2,:].imag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d9b175-ba27-456f-a6de-f64bbe4ee0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/opt/sw/jupyterhub/envs/conda/vsc5/jupyterhub-llm-training-v1/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:647: ComplexWarning:\n",
      "\n",
      "Casting complex values to real discards the imaginary part\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "n = np.linspace(0,999,1000)\n",
    "iv = (2*n+1)/30*np.pi\n",
    "mx = 5\n",
    "\n",
    "fpara_pred = torch.zeros((sort_ek.shape[0], sort_vk.shape[0], 2))\n",
    "fpara_target = torch.zeros((sort_ek.shape[0], sort_vk.shape[0], 2))\n",
    "Z_loss = torch.zeros((sort_ek.shape[0], sort_vk.shape[0]))\n",
    "gamma_loss = torch.zeros((sort_ek.shape[0], sort_vk.shape[0]))\n",
    "\n",
    "\n",
    "for n in range(0,sort_ek.shape[0]):\n",
    "    if n%100==0: print(n)\n",
    "    for m in range(0,sort_vk.shape[0]):\n",
    "        ta2, _ = curve_fit(fit_ImSigma_2, iv[:mx], data_np[n,m,1,:mx].imag)\n",
    "        pe2, _ = curve_fit(fit_ImSigma_2, iv[:mx], data_np[n,m,2,:mx])\n",
    "        fpara_target[n,m,0] = ta2[0]\n",
    "        fpara_target[n,m,1] = ta2[1]\n",
    "        fpara_pred[n,m,0] = pe2[0]\n",
    "        fpara_pred[n,m,1] = pe2[1]\n",
    "\n",
    "        gamma_loss[n,m] = loss(torch.tensor(ta2[0]), torch.tensor(pe2[0]))\n",
    "        Z_loss[n,m] = loss(torch.tensor(ta2[1]), torch.tensor(pe2[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc1489b-6604-4269-a15d-41aaeb9713d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(0,sort_ek.shape[0]):\n",
    "    if n%100==0: print(n)\n",
    "    for m in range(0,sort_vk.shape[0]):\n",
    "        gamma_loss[n,m] = np.sqrt( abs(fpara_target[n,m,0]**2 - fpara_pred[n,m,0]**2) )\n",
    "        Z_loss[n,m] = np.sqrt( abs(fpara_target[n,m,1]**2 - fpara_pred[n,m,1]**2) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485f53ab-2ba5-4a04-97e3-f7e3746cfa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLES = [\"MSE\", \"Gamma Loss\", \"Z Loss\", \"Train/Valid\"]\n",
    "plot3D_4x([mse_loss, gamma_loss, Z_loss, trainvalid],TITLES)\n",
    "TITLES = [\"Zt\", \"Zp\", \"Gt\", \"Gp\"]\n",
    "plot3D_4x([fpara_target[:,:,0], fpara_pred[:,:,0], fpara_target[:,:,1], fpara_pred[:,:,1]], TITLES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8db47e-a0bd-4c0d-a8f6-6c5fbe94ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=3, nrows=1, figsize=(18,4))\n",
    "fign = 0\n",
    "ax[fign].plot(iv[:mx], data_np[450,310,1,:mx].imag)\n",
    "ax[fign].plot(iv[:mx], data_np[450,310,2,:mx], \"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73c6d833-0f14-4e46-9346-48390b42237a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(478.6505) tensor(0.1659) tensor(-21.7122) tensor(478.6504)\n"
     ]
    }
   ],
   "source": [
    "# for n in range(0,sort_ek.shape[0]):\n",
    "#     if n%100==0: print(n)\n",
    "#     for m in range(0,sort_vk.shape[0]):\n",
    "#         print(Z_loss[n,m], fpara_target[n,m,0], fpara_pred[n,m,0])\n",
    "# max_index = np.unravel_index(np.argmax(matrix), matrix.shape)\n",
    "# print(np.unravel_index(np.argmax(Z_loss[:,:]), Z_loss.shape))\n",
    "\n",
    "\n",
    "print(Z_loss[249,30], fpara_target[249,30,1], fpara_pred[249,30,1], loss(fpara_target[249,30,1], fpara_pred[249,30,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2d14af",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample = int(np.random.rand()*len(validation_set))\n",
    "print(random_sample)\n",
    "graph_sample = {}\n",
    "graph_sample[\"node_feature\"] = validation_set[random_sample][\"node_feature\"][None]\n",
    "graph_sample[\"edge_index\"] = validation_set[random_sample][\"edge_index\"][None]\n",
    "graph_sample[\"vectors\"] = validation_set[random_sample][\"vectors\"][None]\n",
    "graph_sample[\"target\"] = validation_set[random_sample][\"target\"][None]\n",
    "pred_ae_1 = model.model(graph_sample)\n",
    "emb_vec = model.model.vec_embedding_mlp(graph_sample[\"vectors\"][0]).detach().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, nrows=1, figsize=(18,4))\n",
    "# print(graph_sample[\"target\"].shape)\n",
    "# print(pred_ae_1.detach().numpy().shape)\n",
    "# print(graph_sample[\"target\"].shape)\n",
    "\n",
    "fign = 0\n",
    "ax[fign].plot(graph_sample[\"target\"][0,:])\n",
    "ax[fign].plot(pred_ae_1.detach().numpy()[:300])\n",
    "\n",
    "# print(graph_sample[\"vectors\"].shape)\n",
    "\n",
    "fign = 1\n",
    "ax[fign].plot(graph_sample[\"node_feature\"][0,12,:])\n",
    "# ax[fign].plot(graph_sample[\"vectors\"][0,2])\n",
    "# ax[fign].plot(graph_sample[\"vectors\"][0,12])\n",
    "# ax[fign].plot(graph_sample[\"vector\"][20])\n",
    "\n",
    "fign = 2\n",
    "ax[fign].plot(emb_vec[110,:])\n",
    "ax[fign].plot(emb_vec[221,:])\n",
    "ax[fign].plot(emb_vec[0,:])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
