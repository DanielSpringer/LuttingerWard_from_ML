{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb48f2e9-5730-45fb-bd57-79294cf57441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"colab\"\n",
    "\n",
    "\n",
    "def plot3D_4x(P, TITLES):\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=4,\n",
    "        specs=[[{'type': 'surface'},{'type': 'surface'},{'type': 'surface'},{'type': 'surface'}]],\n",
    "        subplot_titles=TITLES)# , subplot_titles=(titles))\n",
    "    \n",
    "    omega = 1\n",
    "    q = 41\n",
    "    \n",
    "    fig.add_trace(\n",
    "    go.Surface(z=P[0], colorscale='viridis', showscale=False),\n",
    "    row=1, col=1)\n",
    "    \n",
    "    fig.add_trace(\n",
    "    go.Surface(z=P[1], colorscale='viridis', showscale=False),\n",
    "    row=1, col=2)\n",
    "    \n",
    "    fig.add_trace(\n",
    "    go.Surface(z=P[2], colorscale='viridis', showscale=False),\n",
    "    row=1, col=3)\n",
    "    \n",
    "    fig.add_trace(\n",
    "    go.Surface(z=P[3], colorscale='viridis', showscale=False),\n",
    "    row=1, col=4)\n",
    "    \n",
    "    fig.update_scenes(xaxis_title_text='ek',  \n",
    "                      yaxis_title_text='vk')\n",
    "        \n",
    "    camera = dict(\n",
    "        eye=dict(x=2, y=1.5, z=1.)\n",
    "    )\n",
    "    aspectratio = dict(x=1, y=1., z=1.5)\n",
    "    \n",
    "        \n",
    "    fig.layout.scene1.camera = camera\n",
    "    fig.layout.scene2.camera = camera\n",
    "    fig.layout.scene3.camera = camera\n",
    "    fig.layout.scene4.camera = camera\n",
    "    fig.layout.scene1.aspectratio=aspectratio\n",
    "    fig.layout.scene2.aspectratio=aspectratio\n",
    "    fig.layout.scene3.aspectratio=aspectratio\n",
    "    fig.layout.scene4.aspectratio=aspectratio\n",
    "    \n",
    "    fig.update_layout(\n",
    "        scene1 = dict(zaxis = dict(nticks=4),),\n",
    "        scene2 = dict(zaxis = dict(nticks=4),),\n",
    "        scene3 = dict(zaxis = dict(nticks=4),),\n",
    "        scene4 = dict(zaxis = dict(nticks=4),),\n",
    "        title=r'',\n",
    "        autosize=True,\n",
    "        width=1800, height=600,\n",
    "        margin=dict(l=10, r=5, b=0, t=35))\n",
    "    \n",
    "    fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c38f9a16-ffab-4350-9840-971978aaee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def fit_ImSigma_2(iw, gamma, alpha, beta):\n",
    "    ImSigma = -gamma - alpha * iw - beta * iw**2\n",
    "    return ImSigma\n",
    "\n",
    "def fit_ImSigma_1(iw, gamma, alpha):\n",
    "    ImSigma = gamma - alpha * iw\n",
    "    return ImSigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5a598c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/data/fs72150/springerd/Projects/LuttingerWard_from_ML/saves/GTrans/metiso/U2c0_b30_N250000/save_GNN_basis_2_BS20_2024-08-16/version_0/checkpoints/epoch=95-step=473280.ckpt\n",
      "Dataset_graph_generic\n",
      " Checkpoint loaded...\n",
      " working 1 ...\n",
      " Model loading... \n",
      " Model loaded... \n",
      "...loading done.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import sys, re\n",
    "sys.path.append('/gpfs/data/fs72150/springerd/Projects/LuttingerWard_from_ML/')\n",
    "\n",
    "import torch\n",
    "import json\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "def create_datasets(config):\n",
    "    \n",
    "    PATH = config[\"PATH_TRAIN\"]\n",
    "\n",
    "    # f = h5py.File(PATH, 'r')\n",
    "    # data = np.array(f[\"train\"]['data'][:1000])\n",
    "    # print(\"************************************\")\n",
    "    # print(\"Size of dataset: \", data.shape)\n",
    "    # print(\"************************************\")\n",
    "    # train, validation = torch.utils.data.random_split(data, [int(data.__len__()*0.8), int(data.__len__())-int(data.__len__()*0.8)], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    PATH = config[\"PATH_TRAIN\"]\n",
    "    f = h5py.File(PATH, 'r')\n",
    "    if config[\"TRAINDATA\"]==config[\"VALIDATIONDATA\"]:\n",
    "        data = np.array(f[config[\"TRAINDATA\"]])\n",
    "        train, validation = torch.utils.data.random_split(data, [int(data.__len__()*config[\"SPLIT\"]), int(data.__len__())-int(data.__len__()*config[\"SPLIT\"])], generator=torch.Generator().manual_seed(42))\n",
    "    else:\n",
    "        train = np.array(f[config[\"TRAINDATA\"]])\n",
    "        validation = np.array(f[config[\"VALIDATIONDATA\"]])\n",
    "    \n",
    "    return train, validation\n",
    "\n",
    "def load_model_data(SAVEPATH):\n",
    "    ep = 0\n",
    "    for filename in os.listdir(SAVEPATH+\"checkpoints\"):\n",
    "        epc = int(re.findall(r'\\d+', filename)[0])\n",
    "        # if epc == 0:\n",
    "        #     f = os.path.join(SAVEPATH, filename)\n",
    "        #     FILENAME = \"checkpoints/\"+filename\n",
    "        if epc > ep:\n",
    "            f = os.path.join(SAVEPATH, filename)\n",
    "            FILENAME = \"checkpoints/\"+filename\n",
    "            ep = epc\n",
    "    config = json.load(open(SAVEPATH+'config.json'))\n",
    "    print(SAVEPATH+FILENAME)\n",
    "    print(config[\"DATA_LOADER\"])\n",
    "    checkpoint = torch.load(SAVEPATH+FILENAME, map_location=torch.device('cpu'))\n",
    "    print(\" Checkpoint loaded...\")\n",
    "    \n",
    "    ''' Model setup '''\n",
    "    wrapers = __import__(\"src.wrappers.wrapers\", fromlist=['object'])#.wrapers\n",
    "    print(\" working 1 ...\")\n",
    "    model = getattr(wrapers, config[\"MODEL_WRAPER\"])(config)\n",
    "    print(\" Model loading... \")\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    print(\" Model loaded... \")\n",
    "    # p = kk\n",
    "    # model = 0\n",
    "\n",
    "    ''' Dataloading '''\n",
    "    train_data, validation_data = create_datasets(config)\n",
    "    train_data = np.array(train_data)\n",
    "    validation_data = np.array(validation_data)\n",
    "    \n",
    "    ### > Single HDF5 file containing training and validation data \n",
    "    ld = __import__(\"load_data\", fromlist=['object'])\n",
    "    # data_set = load_data.Dataset_ae(config)\n",
    "    train_set = getattr(ld, config[\"DATA_LOADER\"])(config, train_data)\n",
    "    validation_set = getattr(ld, config[\"DATA_LOADER\"])(config, validation_data)\n",
    "\n",
    "    train_dataloader = DataLoader(train_set, batch_size=22, shuffle=False)\n",
    "    validation_dataloader = DataLoader(validation_set, batch_size=22, shuffle=False)\n",
    "    \n",
    "    # f = h5py.File(config[\"PATH_TRAIN\"], 'r')\n",
    "    # parameters = f[\"valid\"][\"parameters\"]\n",
    "    return model, train_set, validation_set, train_dataloader, validation_dataloader, config\n",
    "\n",
    "SAVEPATH = \"/gpfs/data/fs72150/springerd/Projects/LuttingerWard_from_ML/saves/GTrans/metiso/U2c0_b30_N250000/save_GNN_basis_2_BS20_2024-08-16/version_0/\"\n",
    "model, train_set, validation_set, train_dataloader, validation_dataloader, config = load_model_data(SAVEPATH)\n",
    "model.model.eval()\n",
    "\n",
    "\n",
    "print(\"...loading done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4227894b-50e2-47cf-8f3c-4d9d521d6210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.6224, -0.6014, -0.3686, -0.2688, -0.2144])\n",
      "tensor([-0.4353, -0.1466, -0.0897, -0.0659, -0.0531])\n",
      "tensor([-1.5534, -0.5657, -0.3495, -0.2585, -0.2098])\n",
      "tensor([-0.9864, -1.0119, -0.7367, -0.5675, -0.4635])\n",
      "tensor([-0.6272, -0.2180, -0.1411, -0.1117, -0.0979])\n",
      "tensor([-0.0114, -0.0064, -0.0069, -0.0082, -0.0097])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for n,d in enumerate(train_set):\n",
    "    print(d[\"node_feature\"][0][600:605])\n",
    "    if n == 5: break\n",
    "\n",
    "# print(train_set[0])\n",
    "# for n,d in enumerate(train_dataloader):\n",
    "#     print(d)\n",
    "#     print(d[0][:5])\n",
    "#     if n == 5: break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bec5b1c-b41f-487b-bf7b-3be782e91abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/gpfs/data/fs72150/springerd/Projects/LuttingerWard_from_ML/data/SigmaTrans/U2c0_b30_N250000.hdf5\"\n",
    "f = h5py.File(PATH, 'r')\n",
    "\n",
    "train = np.array(f[\"metiso/data/30.0\"])\n",
    "valid = np.array(f[\"transprox/data/30.0\"])\n",
    "\n",
    "train_para = np.array(f[\"metiso/parameters/30.0\"])\n",
    "valid_para = np.array(f[\"transprox/parameters/30.0\"])\n",
    "\n",
    "# print(valid_para[1])\n",
    "\n",
    "### Unique parameters\n",
    "unique_ek = []\n",
    "unique_vk = [] \n",
    "unique_beta = [] \n",
    "\n",
    "for n,para in enumerate(valid_para):\n",
    "    if para[1] not in unique_ek:\n",
    "        unique_ek.append(para[1])\n",
    "    if para[2] not in unique_vk:\n",
    "        unique_vk.append(para[2])\n",
    "    if para[0] not in unique_beta:\n",
    "        unique_beta.append(para[0])\n",
    "\n",
    "for n,para in enumerate(train_para):\n",
    "    if para[1] not in unique_ek:\n",
    "        unique_ek.append(para[1])\n",
    "    if para[2] not in unique_vk:\n",
    "        unique_vk.append(para[2])\n",
    "    if para[0] not in unique_beta:\n",
    "        unique_beta.append(para[0])\n",
    "\n",
    "unique_beta = np.array(unique_beta)\n",
    "unique_ek = np.array(unique_ek)\n",
    "unique_vk = np.array(unique_vk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "789fd335-dcfd-45bf-97af-46a63f9b3faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "for n,para in enumerate(valid_para):\n",
    "    if para[1] not in data.keys():\n",
    "        data[para[1]] = {}\n",
    "    if para[2] not in data[para[1]].keys():\n",
    "        data[para[1]][para[2]] = {}\n",
    "\n",
    "    data[para[1]][para[2]][\"input\"] = torch.tensor(valid[n][0])\n",
    "    data[para[1]][para[2]][\"target\"] = torch.tensor(valid[n][1])\n",
    "    data[para[1]][para[2]][\"param\"] = [para[1], para[2]]\n",
    "    data[para[1]][para[2]][\"set\"] = 1\n",
    "\n",
    "for n,para in enumerate(train_para):\n",
    "    if para[1] not in data.keys():\n",
    "        data[para[1]] = {}\n",
    "    if para[2] not in data[para[1]].keys():\n",
    "        data[para[1]][para[2]] = {}\n",
    "\n",
    "    data[para[1]][para[2]][\"input\"] = torch.tensor(train[n][0])\n",
    "    data[para[1]][para[2]][\"target\"] = torch.tensor(train[n][1])\n",
    "    data[para[1]][para[2]][\"param\"] = [para[1], para[2]]\n",
    "    data[para[1]][para[2]][\"set\"] = -1\n",
    "\n",
    "sort_ek = np.sort(unique_ek)\n",
    "sort_vk = np.sort(unique_vk)\n",
    "\n",
    "data_np = np.zeros((sort_ek.shape[0],sort_vk.shape[0],3,1000), dtype=complex)\n",
    "para_np = np.zeros((sort_ek.shape[0],sort_vk.shape[0],2))\n",
    "trainvalid = np.zeros((sort_ek.shape[0],sort_vk.shape[0]))\n",
    "\n",
    "\n",
    "for n in range(0,sort_ek.shape[0]):\n",
    "    if n%100==0: print(n)\n",
    "    for m in range(0,sort_vk.shape[0]):\n",
    "        trainvalid[n,m] = data[sort_ek[n]][sort_vk[m]][\"set\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a00c60-ac96-4bcb-a152-4ef8f95df36a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d54233f-dfc4-4f71-877e-37c4bf49c12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.6224, -0.6014, -0.3686, -0.2688, -0.2144])\n",
      "tensor([-0.4353, -0.1466, -0.0897, -0.0659, -0.0531])\n",
      "tensor([-1.5534, -0.5657, -0.3495, -0.2585, -0.2098])\n",
      "tensor([-0.9864, -1.0119, -0.7367, -0.5675, -0.4635])\n",
      "tensor([-0.6272, -0.2180, -0.1411, -0.1117, -0.0979])\n",
      "tensor([-0.0114, -0.0064, -0.0069, -0.0082, -0.0097])\n",
      "tensor([-9.5493, -3.1831, -1.9099, -1.3642, -1.0610], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for n,d in enumerate(train_set):\n",
    "    print(d[\"node_feature\"][0][600:605])\n",
    "    if n == 5: break\n",
    "\n",
    "print(data[sort_ek[0]][sort_vk[0]][\"target\"][:5].imag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beffae8b-ae7f-4731-9dcc-56a2cb0ca231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1259188/2543809242.py:4: DeprecationWarning:\n",
      "\n",
      "__array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "\n",
      "/tmp/ipykernel_1259188/2543809242.py:5: DeprecationWarning:\n",
      "\n",
      "__array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "for n in range(0,sort_ek.shape[0]):\n",
    "    if n%100==0: print(n)\n",
    "    for m in range(0,sort_vk.shape[0]):\n",
    "        data_np[n,m,0,:] = data[sort_ek[n]][sort_vk[m]][\"input\"]\n",
    "        data_np[n,m,1,:] = data[sort_ek[n]][sort_vk[m]][\"target\"]\n",
    "        # data_np[n,m,2,:] = model(data[sort_ek[n]][sort_vk[m]][\"input\"].imag.float()).detach().numpy()\n",
    "        para_np[n,m,0] = sort_ek[n]\n",
    "        para_np[n,m,1] = sort_vk[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4863ca86-d49a-4a06-8b37-eb85a1d2bbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m: \u001b[38;5;28mprint\u001b[39m(n)\n\u001b[1;32m      7\u001b[0m sample1 \u001b[38;5;241m=\u001b[39m data_np[\u001b[38;5;241m0\u001b[39m,:,:\u001b[38;5;241m2\u001b[39m,:]\n\u001b[0;32m----> 8\u001b[0m sample1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mld\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDATA_LOADER\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# print(sample1[n][\"node_feature\"].shape)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# print(sample1[n][\"edge_index\"].shape)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# print(sample1[n][\"vectors\"].shape)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# print(sample1[n][\"target\"].shape)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m graph_sample \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/gpfs/data/fs72150/springerd/Projects/LuttingerWard_from_ML/src/load_data.py:480\u001b[0m, in \u001b[0;36mDataset_graph_generic.__init__\u001b[0;34m(self, config, dataset)\u001b[0m\n\u001b[1;32m    478\u001b[0m         edge_index[\u001b[38;5;241m0\u001b[39m, k] \u001b[38;5;241m=\u001b[39m i\n\u001b[1;32m    479\u001b[0m         edge_index[\u001b[38;5;241m1\u001b[39m, k] \u001b[38;5;241m=\u001b[39m j\n\u001b[0;32m--> 480\u001b[0m         k \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_index \u001b[38;5;241m=\u001b[39m edge_index\u001b[38;5;241m.\u001b[39mlong()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # data_torch = torch.zeros((500,500,300))\n",
    "# ld = __import__(\"load_data\", fromlist=['object'])\n",
    "\n",
    "# for n in range(0,sort_ek.shape[0]):\n",
    "    \n",
    "#     if n%100==0: print(n)\n",
    "#     sample1 = data_np[0,:,:2,:]\n",
    "#     sample1 = getattr(ld, config[\"DATA_LOADER\"])(config, sample1)\n",
    "#     # print(sample1[n][\"node_feature\"].shape)\n",
    "#     # print(sample1[n][\"edge_index\"].shape)\n",
    "#     # print(sample1[n][\"vectors\"].shape)\n",
    "#     # print(sample1[n][\"target\"].shape)\n",
    "#     graph_sample = {}\n",
    "#     graph_sample[\"node_feature\"] = sample1[n][\"node_feature\"]#[None]\n",
    "#     graph_sample[\"edge_index\"] = sample1[n][\"edge_index\"]#[None]\n",
    "#     graph_sample[\"vectors\"] = sample1[n][\"vectors\"]#[None]\n",
    "#     graph_sample[\"target\"] = sample1[n][\"target\"]#[None]\n",
    "\n",
    "#     # for m in range(0,sort_vk.shape[0]):\n",
    "#     #     if m%50==0: print(n,m)\n",
    "#     #     graph_sample[\"node_feature\"] = sample1[m][\"node_feature\"]#[None]\n",
    "#     #     data_torch[n,m,:] = model(graph_sample)#.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e4889c9-75e3-42fa-a475-7e577caf7bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0 0\n",
      "0 50\n",
      "0 100\n",
      "0 150\n",
      "0 200\n",
      "0 250\n",
      "0 300\n",
      "0 350\n",
      "0 400\n",
      "0 450\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 'edge_index' to be two-dimensional (got 3 dimensions)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 21\u001b[0m\n\u001b[1;32m     16\u001b[0m     graph_sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m][m] \u001b[38;5;241m=\u001b[39m sample1[m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;66;03m#[None]\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# graph_sample[\"node_feature\"] = torch.tensor(graph_sample[\"node_feature\"])\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# graph_sample[\"edge_index\"] = torch.tensor(graph_sample[\"edge_index\"])\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# graph_sample[\"vectors\"] = torch.tensor(graph_sample[\"vectors\"])\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# graph_sample[\"target\"] = torch.tensor(graph_sample[\"target\"])\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph_sample\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# data_torch[n,:,:] = model(graph_sample)#.detach().numpy()\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/data/fs72150/springerd/Projects/LuttingerWard_from_ML/src/wrappers/wrapers.py:28\u001b[0m, in \u001b[0;36mmodel_wraper_gnn.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/data/fs72150/springerd/Projects/LuttingerWard_from_ML/src/models/models.py:596\u001b[0m, in \u001b[0;36mGNN_basis_2.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    594\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvec_embedding_mlp(x1)\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layer):\n\u001b[0;32m--> 596\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreen_gnn\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    598\u001b[0m x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_pre_pool(x2)\n\u001b[1;32m    599\u001b[0m batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(x2\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mx2\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/data/fs72150/springerd/Projects/LuttingerWard_from_ML/src/models/models.py:489\u001b[0m, in \u001b[0;36mGNN_Layer_2.forward\u001b[0;34m(self, x, edge_index, v)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, v):\n\u001b[1;32m    488\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Propagate messages along edges \"\"\"\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m     propagate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m propagate\n",
      "File \u001b[0;32m/tmp/models.models_GNN_Layer_2_propagate_u9k0cjl3.py:147\u001b[0m, in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, v, size)\u001b[0m\n\u001b[1;32m    144\u001b[0m             v \u001b[38;5;241m=\u001b[39m hook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# End Propagate Forward Pre Hook ###########################################\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m mutable_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m fuse \u001b[38;5;241m=\u001b[39m is_sparse(edge_index) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuse\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fuse:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:281\u001b[0m, in \u001b[0;36mMessagePassing._check_input\u001b[0;34m(self, edge_index, size)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to be of integer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype (got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00medge_index\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edge_index\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to be two-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00medge_index\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing() \u001b[38;5;129;01mand\u001b[39;00m edge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have size \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe first dimension (got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00medge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 'edge_index' to be two-dimensional (got 3 dimensions)"
     ]
    }
   ],
   "source": [
    "for n in range(0,sort_ek.shape[0]):\n",
    "    \n",
    "    if n%100==0: print(n)\n",
    "    sample1 = data_np[0,:,:2,:]\n",
    "    sample1 = getattr(ld, config[\"DATA_LOADER\"])(config, sample1)\n",
    "    graph_sample = {}\n",
    "    graph_sample[\"node_feature\"] = torch.zeros((500,300, 900))\n",
    "    graph_sample[\"edge_index\"] = torch.zeros((500,2, 90000), dtype=int)\n",
    "    graph_sample[\"vectors\"] = torch.zeros((500,300, 300))\n",
    "    graph_sample[\"target\"] = torch.zeros((500,300))\n",
    "    for m in range(0,sort_vk.shape[0]):\n",
    "        if m%50==0: print(n,m)\n",
    "        graph_sample[\"node_feature\"][m] = sample1[m][\"node_feature\"].float()#[None]\n",
    "        graph_sample[\"edge_index\"][m] = sample1[m][\"edge_index\"].float()#[None]\n",
    "        graph_sample[\"vectors\"][m] = sample1[m][\"vectors\"].float()#[None]\n",
    "        graph_sample[\"target\"][m] = sample1[m][\"target\"].float()#[None]\n",
    "    # graph_sample[\"node_feature\"] = torch.tensor(graph_sample[\"node_feature\"])\n",
    "    # graph_sample[\"edge_index\"] = torch.tensor(graph_sample[\"edge_index\"])\n",
    "    # graph_sample[\"vectors\"] = torch.tensor(graph_sample[\"vectors\"])\n",
    "    # graph_sample[\"target\"] = torch.tensor(graph_sample[\"target\"])\n",
    "    print(model(graph_sample).shape)\n",
    "    break\n",
    "    # data_torch[n,:,:] = model(graph_sample)#.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a931bf3d-60e8-4463-9943-32f3671cabf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ivmax = 300\n",
    "loss = torch.nn.MSELoss()\n",
    "mse_loss = torch.zeros((sort_ek.shape[0], sort_vk.shape[0]))\n",
    "for n in range(0,sort_ek.shape[0]):\n",
    "    if n%100==0: print(n)\n",
    "    for m in range(0,sort_vk.shape[0]):\n",
    "        mse_loss[n,m] = loss(torch.tensor(data_np[n,m,1,:ivmax].imag), torch.tensor(data_np[n,m,2,:ivmax].imag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d9b175-ba27-456f-a6de-f64bbe4ee0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.linspace(0,999,1000)\n",
    "iv = (2*n+1)/30*np.pi\n",
    "mx = 5\n",
    "\n",
    "fpara_pred = torch.zeros((sort_ek.shape[0], sort_vk.shape[0], 2))\n",
    "fpara_target = torch.zeros((sort_ek.shape[0], sort_vk.shape[0], 2))\n",
    "Z_loss = torch.zeros((sort_ek.shape[0], sort_vk.shape[0]))\n",
    "gamma_loss = torch.zeros((sort_ek.shape[0], sort_vk.shape[0]))\n",
    "\n",
    "\n",
    "for n in range(0,sort_ek.shape[0]):\n",
    "    if n%100==0: print(n)\n",
    "    for m in range(0,sort_vk.shape[0]):\n",
    "        ta2, _ = curve_fit(fit_ImSigma_2, iv[:mx], data_np[n,m,1,:mx].imag)\n",
    "        pe2, _ = curve_fit(fit_ImSigma_2, iv[:mx], data_np[n,m,2,:mx])\n",
    "        fpara_target[n,m,0] = ta2[0]\n",
    "        fpara_target[n,m,1] = ta2[1]\n",
    "        fpara_pred[n,m,0] = pe2[0]\n",
    "        fpara_pred[n,m,1] = pe2[1]\n",
    "\n",
    "        gamma_loss[n,m] = loss(torch.tensor(ta2[0]), torch.tensor(pe2[0]))\n",
    "        Z_loss[n,m] = loss(torch.tensor(ta2[1]), torch.tensor(pe2[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc1489b-6604-4269-a15d-41aaeb9713d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(0,sort_ek.shape[0]):\n",
    "    if n%100==0: print(n)\n",
    "    for m in range(0,sort_vk.shape[0]):\n",
    "        gamma_loss[n,m] = np.sqrt( abs(fpara_target[n,m,0]**2 - fpara_pred[n,m,0]**2) )\n",
    "        Z_loss[n,m] = np.sqrt( abs(fpara_target[n,m,1]**2 - fpara_pred[n,m,1]**2) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485f53ab-2ba5-4a04-97e3-f7e3746cfa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLES = [\"MSE\", \"Gamma Loss\", \"Z Loss\", \"Train/Valid\"]\n",
    "plot3D_4x([mse_loss, gamma_loss, Z_loss, trainvalid],TITLES)\n",
    "TITLES = [\"Zt\", \"Zp\", \"Gt\", \"Gp\"]\n",
    "plot3D_4x([fpara_target[:,:,0], fpara_pred[:,:,0], fpara_target[:,:,1], fpara_pred[:,:,1]], TITLES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f75056-57d8-47db-88c7-6d7c949ce1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 30\n",
    "n = np.linspace(0,999,1000)\n",
    "iv = (2*n+1)/30*np.pi\n",
    "mx = 5\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, nrows=1, figsize=(18,4))\n",
    "fign = 0\n",
    "ax[fign].plot(iv[:mx], data_np[450,310,1,:mx].imag)\n",
    "ax[fign].plot(iv[:mx], data_np[450,310,2,:mx], \"--\")\n",
    "\n",
    "fign = 1\n",
    "mx = 1000\n",
    "ax[fign].plot(iv[:mx], data_np[450,310,1,:mx].imag)\n",
    "ax[fign].plot(iv[:mx], data_np[450,310,2,:mx], \"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c6d833-0f14-4e46-9346-48390b42237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n in range(0,sort_ek.shape[0]):\n",
    "#     if n%100==0: print(n)\n",
    "#     for m in range(0,sort_vk.shape[0]):\n",
    "#         print(Z_loss[n,m], fpara_target[n,m,0], fpara_pred[n,m,0])\n",
    "# max_index = np.unravel_index(np.argmax(matrix), matrix.shape)\n",
    "# print(np.unravel_index(np.argmax(Z_loss[:,:]), Z_loss.shape))\n",
    "\n",
    "\n",
    "print(Z_loss[249,30], fpara_target[249,30,1], fpara_pred[249,30,1], loss(fpara_target[249,30,1], fpara_pred[249,30,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2d14af",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample = int(np.random.rand()*len(validation_set))\n",
    "print(random_sample)\n",
    "graph_sample = {}\n",
    "graph_sample[\"node_feature\"] = validation_set[random_sample][\"node_feature\"][None]\n",
    "graph_sample[\"edge_index\"] = validation_set[random_sample][\"edge_index\"][None]\n",
    "graph_sample[\"vectors\"] = validation_set[random_sample][\"vectors\"][None]\n",
    "graph_sample[\"target\"] = validation_set[random_sample][\"target\"][None]\n",
    "pred_ae_1 = model.model(graph_sample)\n",
    "emb_vec = model.model.vec_embedding_mlp(graph_sample[\"vectors\"][0]).detach().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, nrows=1, figsize=(18,4))\n",
    "# print(graph_sample[\"target\"].shape)\n",
    "# print(pred_ae_1.detach().numpy().shape)\n",
    "# print(graph_sample[\"target\"].shape)\n",
    "\n",
    "fign = 0\n",
    "ax[fign].plot(graph_sample[\"target\"][0,:])\n",
    "ax[fign].plot(pred_ae_1.detach().numpy()[:300])\n",
    "\n",
    "# print(graph_sample[\"vectors\"].shape)\n",
    "\n",
    "fign = 1\n",
    "ax[fign].plot(graph_sample[\"node_feature\"][0,12,:])\n",
    "# ax[fign].plot(graph_sample[\"vectors\"][0,2])\n",
    "# ax[fign].plot(graph_sample[\"vectors\"][0,12])\n",
    "# ax[fign].plot(graph_sample[\"vector\"][20])\n",
    "\n",
    "fign = 2\n",
    "ax[fign].plot(emb_vec[110,:])\n",
    "ax[fign].plot(emb_vec[221,:])\n",
    "ax[fign].plot(emb_vec[0,:])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
